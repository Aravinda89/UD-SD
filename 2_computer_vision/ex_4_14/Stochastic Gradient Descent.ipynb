{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b99bbc-fc7b-4b58-a0a8-41deefe48697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset import get_datasets\n",
    "from logistic import softmax, cross_entropy, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ccb8113-a369-42da-9af9-0541ee2efcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, grads, lr, bs):\n",
    "    \"\"\"\n",
    "    stochastic gradient descent implementation\n",
    "    args:\n",
    "    - params [list[tensor]]: model params\n",
    "    - grad [list[tensor]]: param gradient\n",
    "    - lr [float]: learning rate\n",
    "    - bs [int]: batch_size\n",
    "    \"\"\"\n",
    "    for param, grad in zip(params, grads):\n",
    "        param.assign_sub(lr * grad / bs)\n",
    "\n",
    "\n",
    "def training_loop(lr):\n",
    "    \"\"\"\n",
    "    training loop\n",
    "    args:\n",
    "    - lr [float]: learning rate\n",
    "    returns:\n",
    "    - mean_acc [tensor]: training accuracy\n",
    "    - mean_loss [tensor]: training loss\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for X, Y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            X = X / 255.0\n",
    "            y_hat = model(X)\n",
    "            # calculate loss\n",
    "            one_hot = tf.one_hot(Y, 43)\n",
    "            loss = cross_entropy(y_hat, one_hot)\n",
    "            losses.append(tf.math.reduce_mean(loss))\n",
    "\n",
    "            grads = tape.gradient(loss, [W, b])\n",
    "            sgd([W, b], grads, lr, X.shape[0]) \n",
    "\n",
    "            acc = accuracy(y_hat, Y)\n",
    "            accuracies.append(acc)\n",
    "    mean_acc = tf.math.reduce_mean(tf.concat(accuracies, axis=0))\n",
    "    mean_loss = tf.math.reduce_mean(losses)\n",
    "    return mean_loss, mean_acc\n",
    "\n",
    "def model(X):\n",
    "    \"\"\"\n",
    "    logistic regression model\n",
    "    \"\"\"\n",
    "    flatten_X = tf.reshape(X, (-1, W.shape[0]))\n",
    "    return softmax(tf.matmul(flatten_X, W) + b)\n",
    "\n",
    "    \n",
    "def validation_loop():\n",
    "    \"\"\"\n",
    "    loop through the validation dataset\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    for X, Y in val_dataset:\n",
    "        X = X / 255.0\n",
    "        y_hat = model(X)\n",
    "        acc = accuracy(y_hat, Y)\n",
    "        accuracies.append(acc)\n",
    "    mean_acc = tf.math.reduce_mean(tf.concat(accuracies, axis=0))\n",
    "    return mean_acc\n",
    "\n",
    "\n",
    "def get_module_logger(mod_name):\n",
    "    logger = logging.getLogger(mod_name)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "# if __name__  == '__main__':\n",
    "#     logger = get_module_logger(__name__)\n",
    "#     parser = argparse.ArgumentParser(description='Download and process tf files')\n",
    "#     parser.add_argument('--imdir', required=True, type=str,\n",
    "#                         help='data directory')\n",
    "#     parser.add_argument('--epochs', default=10, type=int,\n",
    "#                         help='Number of epochs')\n",
    "#     args = parser.parse_args()    \n",
    "\n",
    "#     logger.info(f'Training for {args.epochs} epochs using {args.imdir} data')\n",
    "#     # get the datasets\n",
    "#     train_dataset, val_dataset = get_datasets(args.imdir)\n",
    "\n",
    "#     # set the variables\n",
    "#     num_inputs = 1024*3\n",
    "#     num_outputs = 43\n",
    "#     W = tf.Variable(tf.random.normal(shape=(num_inputs, num_outputs),\n",
    "#                                     mean=0, stddev=0.01))\n",
    "#     b = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "#     lr = 0.1\n",
    "#     # training! \n",
    "#     for epoch in range(args.epochs):\n",
    "#         logger.info(f'Epoch {epoch}')\n",
    "#         loss, acc = training_loop(lr)\n",
    "#         logger.info(f'Mean training loss: {loss:1f}, mean training accuracy {acc:1f}')\n",
    "#         val_acc = validation_loop()\n",
    "#         logger.info(f'Mean validation accuracy {val_acc:1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b6c799-48ef-40fd-9b24-0637ca0387d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "imdir='./GTSRB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26ed6b3-6870-4bd8-ae60-cfd40a72f19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 21:57:07,845 INFO     Training for 1 epochs using ./GTSRB data\n"
     ]
    }
   ],
   "source": [
    "logger = get_module_logger(__name__)\n",
    "logger.info(f'Training for {epochs} epochs using {imdir} data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419d6dfd-8c46-4d5b-b14a-626e986a825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4300 files belonging to 1 classes.\n",
      "Using 3870 files for training.\n",
      "Found 4300 files belonging to 1 classes.\n",
      "Using 430 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = get_datasets(imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69decace-a43b-41f2-b3e3-d898c8b00489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8edbf68f-d150-4bd8-aa81-9515e4ccccca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab5d116-e99c-4202-be6e-006b4b065236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables\n",
    "num_inputs = 1024*3\n",
    "num_outputs = 43\n",
    "\n",
    "W = tf.Variable(tf.random.normal(shape=(num_inputs, num_outputs),mean=0, stddev=0.01))\n",
    "b = tf.Variable(tf.zeros(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20c8064-9846-45de-a7ee-aae52bb9b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3072, 43])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff001404-b4d0-4c29-bb00-91c27838cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([43])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd124665-474f-4adb-aea9-4dbcb39df86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 22:04:47,540 INFO     Epoch 0\n",
      "2025-03-27 22:04:49,930 INFO     Mean training loss: 0.306262, mean training accuracy 0.983607\n",
      "2025-03-27 22:04:50,179 INFO     Mean validation accuracy 1.000000\n",
      "2025-03-27 22:04:50,179 INFO     Epoch 1\n",
      "2025-03-27 22:04:53,668 INFO     Mean training loss: 0.086758, mean training accuracy 1.000000\n",
      "2025-03-27 22:04:54,045 INFO     Mean validation accuracy 1.000000\n",
      "2025-03-27 22:04:54,045 INFO     Epoch 2\n",
      "2025-03-27 22:04:57,932 INFO     Mean training loss: 0.060019, mean training accuracy 1.000000\n",
      "2025-03-27 22:04:58,326 INFO     Mean validation accuracy 1.000000\n",
      "2025-03-27 22:04:58,330 INFO     Epoch 3\n",
      "2025-03-27 22:05:02,242 INFO     Mean training loss: 0.047434, mean training accuracy 1.000000\n",
      "2025-03-27 22:05:02,635 INFO     Mean validation accuracy 1.000000\n",
      "2025-03-27 22:05:02,643 INFO     Epoch 4\n",
      "2025-03-27 22:05:06,531 INFO     Mean training loss: 0.039319, mean training accuracy 1.000000\n",
      "2025-03-27 22:05:06,885 INFO     Mean validation accuracy 1.000000\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epochs=5\n",
    "\n",
    "# training! \n",
    "for epoch in range(epochs):\n",
    "    logger.info(f'Epoch {epoch}')\n",
    "    loss, acc = training_loop(lr)\n",
    "    logger.info(f'Mean training loss: {loss:1f}, mean training accuracy {acc:1f}')\n",
    "    val_acc = validation_loop()\n",
    "    logger.info(f'Mean validation accuracy {val_acc:1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
